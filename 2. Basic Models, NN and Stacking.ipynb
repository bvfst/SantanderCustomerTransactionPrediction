{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16b07419",
   "metadata": {},
   "source": [
    "## Predictive Analytics Project - Santander Customer Transaction Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabd1da2",
   "metadata": {},
   "source": [
    "## Basic Predictive Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73b7e2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### All imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.regularizers import L1L2\n",
    "from lightgbm import LGBMClassifier as lgb\n",
    "# import lightgbm as lgb\n",
    "\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e7c291d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load file and explore\n",
    "train_data = pd.read_csv(\"D:\\\\Academics\\\\UMN-MSBA\\\\Term 2\\\\MSBA 6420 - Predictive Analytics\\\\Project\\\\train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aece36d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"D:\\\\Academics\\\\UMN-MSBA\\\\Term 2\\\\MSBA 6420 - Predictive Analytics\\\\Project\\\\test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e07e922a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = train_data.drop(['ID_code',\t'target'], 1)\n",
    "df_test = test_data.drop(['ID_code'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00b71669",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Seperation\n",
    "X = train_data.drop(['ID_code',\t'target'], 1)\n",
    "y = train_data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17a3c06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55b653c",
   "metadata": {},
   "source": [
    "#### Feature creation from EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0838a7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of real samples in test set is 100000\n",
      "Number of synthetic samples in test set is 100000\n",
      "Training set shape after creating magic features: (200000, 1000)\n",
      "Test set shape after creating magic features: (200000, 1000)\n"
     ]
    }
   ],
   "source": [
    "# Real/Synthetic data\n",
    "# test = df_test.drop(['ID_code'], axis=1).values\n",
    "test = df_test\n",
    "unique_count = np.zeros_like(test)\n",
    "for feature in range(test.shape[1]):\n",
    "    _, index, count = np.unique(test.iloc[:, feature], return_counts=True, return_index=True)\n",
    "    unique_count[index[count == 1], feature] += 1\n",
    "real_samples = np.argwhere(np.sum(unique_count, axis=1) > 0)[:, 0]\n",
    "synth_samples = np.argwhere(np.sum(unique_count, axis=1) == 0)[:, 0]\n",
    "print('Number of real samples in test set is {}'.format(len(real_samples)))\n",
    "print('Number of synthetic samples in test set is {}'.format(len(synth_samples)))\n",
    "\n",
    "features = [col for col in df_train.columns if col.startswith('var')]\n",
    "df_all = pd.concat([df_train, df_test.iloc[real_samples]])\n",
    "for feature in features:\n",
    "    temp = df_all[feature].value_counts(dropna=True)\n",
    "    df_train[feature + 'vc'] = df_train[feature].map(temp).map(lambda x: min(10, x)).astype(np.uint8)\n",
    "    df_test[feature + 'vc'] = df_test[feature].map(temp).map(lambda x: min(10, x)).astype(np.uint8)\n",
    "    df_train[feature + 'sum'] = ((df_train[feature] - df_all[feature].mean()) * df_train[feature + 'vc'] \\\n",
    "                                 .map(lambda x: int(x > 1))).astype(np.float32)\n",
    "    df_test[feature + 'sum'] = ((df_test[feature] - df_all[feature].mean()) * df_test[feature + 'vc'] \\\n",
    "                                .map(lambda x: int(x > 1))).astype(np.float32)\n",
    "    df_train[feature + 'sum2'] = ((df_train[feature]) * df_train[feature + 'vc'] \\\n",
    "                                  .map(lambda x: int(x > 2))).astype(np.float32)\n",
    "    df_test[feature + 'sum2'] = ((df_test[feature]) * df_test[feature + 'vc'] \\\n",
    "                                 .map(lambda x: int(x > 2))).astype(np.float32)\n",
    "    df_train[feature + 'sum3'] = ((df_train[feature]) * df_train[feature + 'vc'] \\\n",
    "                                  .map(lambda x: int(x > 4))).astype(np.float32)\n",
    "    df_test[feature + 'sum3'] = ((df_test[feature]) * df_test[feature + 'vc'] \\\n",
    "                                 .map(lambda x: int(x > 4))).astype(np.float32)\n",
    "print('Training set shape after creating magic features: {}'.format(df_train.shape))\n",
    "print('Test set shape after creating magic features: {}'.format(df_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b20a3ca",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca4bf7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_train, y, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa2f236",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "395c45f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pipeline creation for scaling\n",
    "lr = LogisticRegression()\n",
    "pipe_lr = Pipeline([('sc', StandardScaler()), ('lr', lr)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af79b735",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bayes search for best parameters\n",
    "bayes_cv_tuner_lr = BayesSearchCV(estimator = pipe_lr,\n",
    "                                    search_spaces = {\n",
    "                                                        'lr__class_weight': ['balanced'],\n",
    "                                                        'lr__C': np.logspace(-5, 5, 11),\n",
    "                                                         'lr__l1_ratio': np.logspace(-5, 0, 6),\n",
    "                                                         'lr__penalty': ['elasticnet'],\n",
    "                                                         'lr__solver': ['saga']\n",
    "                                                    },\n",
    "                                    scoring = 'roc_auc',\n",
    "                                    cv = StratifiedKFold(\n",
    "                                        n_splits=3,\n",
    "                                        shuffle=True,\n",
    "                                        random_state=42\n",
    "                                    ),\n",
    "                                    n_jobs = 3,\n",
    "                                    n_iter = 10,\n",
    "                                    verbose = 4,\n",
    "                                    refit = True,\n",
    "                                    random_state = 42\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fef2e3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BayesSearchCV(cv=StratifiedKFold(n_splits=3, random_state=42, shuffle=True),\n",
       "              estimator=Pipeline(steps=[('sc', StandardScaler()),\n",
       "                                        ('lr', LogisticRegression())]),\n",
       "              n_iter=10, n_jobs=3, random_state=42, scoring='roc_auc',\n",
       "              search_spaces={'lr__C': array([1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02,\n",
       "       1.e+03, 1.e+04, 1.e+05]),\n",
       "                             'lr__class_weight': ['balanced'],\n",
       "                             'lr__l1_ratio': array([1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00]),\n",
       "                             'lr__penalty': ['elasticnet'],\n",
       "                             'lr__solver': ['saga']},\n",
       "              verbose=4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_cv_tuner_lr.fit(X = X_train, y = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f004bc2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('lr__C', 0.1),\n",
       "             ('lr__class_weight', 'balanced'),\n",
       "             ('lr__l1_ratio', 1.0),\n",
       "             ('lr__penalty', 'elasticnet'),\n",
       "             ('lr__solver', 'saga')])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_cv_tuner_lr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9dcb923",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = bayes_cv_tuner_lr.predict_proba(X = X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38a9776c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8803438100747146"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_pred_test[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3def1c",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ee01818",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bayes search for best parameters\n",
    "bayes_cv_tuner_dt = BayesSearchCV(estimator = DecisionTreeClassifier(),\n",
    "                                    search_spaces = {\n",
    "                                                        'class_weight': ['balanced'],\n",
    "                                                        'criterion': ['gini'],\n",
    "                                                        'max_depth': [1,2,3,4,5,6,7,8,9,10],\n",
    "                                                        'max_leaf_nodes': [2,3,4,5,6,7,8,9,10],\n",
    "                                                        'min_samples_leaf': [2,3,4,5,6,7,8,9,10],\n",
    "                                                        'min_samples_split': [2,3,4,5,6,7,8,9,10]\n",
    "                                                    },\n",
    "                                    scoring = 'roc_auc',\n",
    "                                    cv = StratifiedKFold(\n",
    "                                        n_splits=3,\n",
    "                                        shuffle=True,\n",
    "                                        random_state=42\n",
    "                                    ),\n",
    "                                    n_jobs = 3,\n",
    "                                    n_iter = 15,\n",
    "                                    verbose = 100,\n",
    "                                    refit = True,\n",
    "                                    random_state = 42\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74e208f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BayesSearchCV(cv=StratifiedKFold(n_splits=3, random_state=42, shuffle=True),\n",
       "              estimator=DecisionTreeClassifier(), n_iter=15, n_jobs=3,\n",
       "              random_state=42, scoring='roc_auc',\n",
       "              search_spaces={'class_weight': ['balanced'],\n",
       "                             'criterion': ['gini'],\n",
       "                             'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
       "                             'max_leaf_nodes': [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
       "                             'min_samples_leaf': [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
       "                             'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10]},\n",
       "              verbose=100)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_cv_tuner_dt.fit(X = X_train, y = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7964cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('class_weight', 'balanced'),\n",
       "             ('criterion', 'gini'),\n",
       "             ('max_depth', 5),\n",
       "             ('max_leaf_nodes', 9),\n",
       "             ('min_samples_leaf', 5),\n",
       "             ('min_samples_split', 2)])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_cv_tuner_dt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb904dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(criterion  = 'gini',\n",
    "                            class_weight = 'balanced',\n",
    "                         max_depth = 5,\n",
    "                         max_leaf_nodes = 9,\n",
    "                         min_samples_leaf = 5,\n",
    "                         min_samples_split = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "531e0e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight='balanced', max_depth=5, max_leaf_nodes=9,\n",
       "                       min_samples_leaf=5)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.fit(X = X_train, y = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "90367871",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final_pred = dt.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67bedfa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6338731462947962"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_final_pred[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa66e15",
   "metadata": {},
   "source": [
    "## NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c1a01a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Best Parameters taken from Neural Network File\n",
    "def build_model():\n",
    "    model = keras.Sequential()\n",
    "    model.add(Dense(288, activation = 'relu', input_dim = 1000))\n",
    "    # model.add(Dropout(0.2))\n",
    "    model.add(Dense(512, activation = 'relu'))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    auc = AUC()\n",
    "    model.compile(\n",
    "        optimizer='adam', #learning_rate = 0.0003069273045576997),\n",
    "        loss = \"binary_crossentropy\",\n",
    "        metrics = [auc]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model2 = KerasClassifier(build_fn = build_model, verbose = 2, epochs = 5, shuffle = False)# , class_weight = {0:1, 1:10})\n",
    "pipe_nn = Pipeline([('nn', model2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a8ebd994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5625/5625 - 14s - loss: 0.9902 - auc: 0.8264 - 14s/epoch - 2ms/step\n",
      "Epoch 2/20\n",
      "5625/5625 - 13s - loss: 0.8840 - auc: 0.8607 - 13s/epoch - 2ms/step\n",
      "Epoch 3/20\n",
      "5625/5625 - 14s - loss: 0.8694 - auc: 0.8657 - 14s/epoch - 2ms/step\n",
      "Epoch 4/20\n",
      "5625/5625 - 13s - loss: 0.8559 - auc: 0.8701 - 13s/epoch - 2ms/step\n",
      "Epoch 5/20\n",
      "5625/5625 - 14s - loss: 0.8477 - auc: 0.8727 - 14s/epoch - 2ms/step\n",
      "Epoch 6/20\n",
      "5625/5625 - 14s - loss: 0.8418 - auc: 0.8746 - 14s/epoch - 2ms/step\n",
      "Epoch 7/20\n",
      "5625/5625 - 14s - loss: 0.8358 - auc: 0.8765 - 14s/epoch - 2ms/step\n",
      "Epoch 8/20\n",
      "5625/5625 - 14s - loss: 0.8313 - auc: 0.8778 - 14s/epoch - 2ms/step\n",
      "Epoch 9/20\n",
      "5625/5625 - 13s - loss: 0.8271 - auc: 0.8791 - 13s/epoch - 2ms/step\n",
      "Epoch 10/20\n",
      "5625/5625 - 13s - loss: 0.8234 - auc: 0.8803 - 13s/epoch - 2ms/step\n",
      "Epoch 11/20\n",
      "5625/5625 - 14s - loss: 0.8220 - auc: 0.8807 - 14s/epoch - 2ms/step\n",
      "Epoch 12/20\n",
      "5625/5625 - 14s - loss: 0.8196 - auc: 0.8814 - 14s/epoch - 2ms/step\n",
      "Epoch 13/20\n",
      "5625/5625 - 14s - loss: 0.8166 - auc: 0.8823 - 14s/epoch - 2ms/step\n",
      "Epoch 14/20\n",
      "5625/5625 - 14s - loss: 0.8170 - auc: 0.8822 - 14s/epoch - 2ms/step\n",
      "Epoch 15/20\n",
      "5625/5625 - 14s - loss: 0.8132 - auc: 0.8832 - 14s/epoch - 2ms/step\n",
      "Epoch 16/20\n",
      "5625/5625 - 14s - loss: 0.8123 - auc: 0.8836 - 14s/epoch - 2ms/step\n",
      "Epoch 17/20\n",
      "5625/5625 - 14s - loss: 0.8094 - auc: 0.8843 - 14s/epoch - 2ms/step\n",
      "Epoch 18/20\n",
      "5625/5625 - 14s - loss: 0.8074 - auc: 0.8849 - 14s/epoch - 2ms/step\n",
      "Epoch 19/20\n",
      "5625/5625 - 14s - loss: 0.8070 - auc: 0.8851 - 14s/epoch - 3ms/step\n",
      "Epoch 20/20\n",
      "5625/5625 - 14s - loss: 0.8042 - auc: 0.8858 - 14s/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('nn',\n",
       "                 <keras.wrappers.scikit_learn.KerasClassifier object at 0x0000027D9C2FB9D0>)])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_nn.fit(X = X_train, y = y_train, nn__epochs = 20, nn__class_weight = {0:1, 1:10}, nn__shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "566b1472",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final_pred = pipe_nn.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ed2f6312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8756306001347883"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_final_pred[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f277da1",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3acb2853",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bayes search for best parameters\n",
    "bayes_cv_tuner_rf = BayesSearchCV(estimator = RandomForestClassifier(),\n",
    "                                    search_spaces = {\n",
    "                                                        'class_weight': ['balanced'],\n",
    "                                                        'criterion': ['gini'],\n",
    "                                                        'max_depth': [1,2,3,4,5,6,7,8,9,10],\n",
    "                                                        'max_leaf_nodes': [2,3,4,5,6,7,8,9,10],\n",
    "                                                        'min_samples_leaf': [2,3,4,5,6,7,8,9,10],\n",
    "                                                        'min_samples_split': [2,3,4,5,6,7,8,9,10]\n",
    "                                                    },\n",
    "                                    scoring = 'roc_auc',\n",
    "                                    cv = StratifiedKFold(\n",
    "                                        n_splits=3,\n",
    "                                        shuffle=True,\n",
    "                                        random_state=42\n",
    "                                    ),\n",
    "                                    n_jobs = 3,\n",
    "                                    n_iter = 15,\n",
    "                                    verbose = 100,\n",
    "                                    refit = True,\n",
    "                                    random_state = 42\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8be8c377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BayesSearchCV(cv=StratifiedKFold(n_splits=3, random_state=42, shuffle=True),\n",
       "              estimator=RandomForestClassifier(), n_iter=15, n_jobs=3,\n",
       "              random_state=42, scoring='roc_auc',\n",
       "              search_spaces={'class_weight': ['balanced'],\n",
       "                             'criterion': ['gini'],\n",
       "                             'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
       "                             'max_leaf_nodes': [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
       "                             'min_samples_leaf': [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
       "                             'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10]},\n",
       "              verbose=100)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_cv_tuner_rf.fit(X = X_train, y = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "89428e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('class_weight', 'balanced'),\n",
       "             ('criterion', 'gini'),\n",
       "             ('max_depth', 6),\n",
       "             ('max_leaf_nodes', 8),\n",
       "             ('min_samples_leaf', 6),\n",
       "             ('min_samples_split', 3)])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_cv_tuner_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "569767bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final_pred = bayes_cv_tuner_rf.predict_proba(X = X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a684de9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6938715045677362"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_final_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879b962c",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "38ae9a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4f05a289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(X = X_train, y = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b2597259",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nb.predict_proba(X = X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c5215774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8044284938302064"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_pred[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1f8a48",
   "metadata": {},
   "source": [
    "## Stacking Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fccb873",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Best Logistic Regression Model\n",
    "lr_best = LogisticRegression(C= 0.1,\n",
    "                             class_weight= 'balanced',\n",
    "                             l1_ratio= 1,\n",
    "                             penalty= 'elasticnet',\n",
    "                             solver= 'saga')\n",
    "pipe_lr_best = Pipeline([('sc', StandardScaler()), ('lr', lr_best)])\n",
    "\n",
    "## Naive Bayes\n",
    "nb = GaussianNB()\n",
    "\n",
    "## Best Decision Tree Model\n",
    "dt = DecisionTreeClassifier(criterion  = 'gini',\n",
    "                            class_weight = 'balanced',\n",
    "                            max_depth = 5,\n",
    "                            max_leaf_nodes = 9,\n",
    "                            min_samples_leaf = 5,\n",
    "                            min_samples_split = 2)\n",
    "\n",
    "## Best Random Forest Model\n",
    "rf = RandomForestClassifier(class_weight = 'balanced',\n",
    "                            criterion = 'gini',\n",
    "                            max_depth = 6,\n",
    "                            max_leaf_nodes = 8,\n",
    "                            min_samples_leaf = 6,\n",
    "                            min_samples_split = 3\n",
    "                           )\n",
    "\n",
    "## Best parameters taken from LGBM file\n",
    "lgbm = lgb(boost_from_average = True,\n",
    "          colsample_bytree = 0.5178695836798571,\n",
    "          is_unbalance = True,\n",
    "          learning_rate = 0.1,\n",
    "          max_depth = -1,\n",
    "          metric = 'auc',\n",
    "          min_data_in_leaf = 143,\n",
    "          num_leaves = 151,\n",
    "          objective = 'binary',\n",
    "          subsample = 1,\n",
    "          subsample_freq = 7          \n",
    "         )\n",
    "\n",
    "### Best Neural Network Model\n",
    "def build_model():\n",
    "    model = keras.Sequential()\n",
    "    model.add(Dense(288, activation = 'relu', input_dim = 1000))\n",
    "    model.add(Dense(512, activation = 'relu'))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    auc = AUC()\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss = \"binary_crossentropy\",\n",
    "        metrics = [auc]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model2 = KerasClassifier(build_fn = build_model, verbose = 2, epochs = 8, shuffle = False, class_weight = {0:1, 1:10})\n",
    "model2._estimator_type = 'classifier'\n",
    "pipe_nn = Pipeline([('nn', model2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80f06152",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Base estimators chosen as LR, NN, NB, RF and DT with final Estimator as LGBM\n",
    "est = [('lr', pipe_lr_best), ('nn', pipe_nn), ('nb', nb), ('rf', rf), ('dt', dt)]\n",
    "final_estimator = lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ed4665d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stacking CLassifier with passthrough True as Passthrough False might not be enough for predictions\n",
    "stack = StackingClassifier(estimators = est,\n",
    "                           final_estimator = final_estimator,\n",
    "                           passthrough = True,\n",
    "                           stack_method = 'predict_proba',\n",
    "                           verbose = 4,\n",
    "                           n_jobs = 1\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b65790e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "5625/5625 - 13s - loss: 0.9901 - auc: 0.8262 - 13s/epoch - 2ms/step\n",
      "Epoch 2/8\n",
      "5625/5625 - 12s - loss: 0.8856 - auc: 0.8600 - 12s/epoch - 2ms/step\n",
      "Epoch 3/8\n",
      "5625/5625 - 12s - loss: 0.8678 - auc: 0.8662 - 12s/epoch - 2ms/step\n",
      "Epoch 4/8\n",
      "5625/5625 - 12s - loss: 0.8554 - auc: 0.8703 - 12s/epoch - 2ms/step\n",
      "Epoch 5/8\n",
      "5625/5625 - 12s - loss: 0.8471 - auc: 0.8729 - 12s/epoch - 2ms/step\n",
      "Epoch 6/8\n",
      "5625/5625 - 12s - loss: 0.8417 - auc: 0.8746 - 12s/epoch - 2ms/step\n",
      "Epoch 7/8\n",
      "5625/5625 - 13s - loss: 0.8388 - auc: 0.8756 - 13s/epoch - 2ms/step\n",
      "Epoch 8/8\n",
      "5625/5625 - 13s - loss: 0.8341 - auc: 0.8771 - 13s/epoch - 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.4min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  4.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  7.3min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 12.2min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "4500/4500 - 10s - loss: 1.0721 - auc_1: 0.8147 - 10s/epoch - 2ms/step\n",
      "Epoch 2/8\n",
      "4500/4500 - 10s - loss: 0.9148 - auc_1: 0.8503 - 10s/epoch - 2ms/step\n",
      "Epoch 3/8\n",
      "4500/4500 - 10s - loss: 0.8820 - auc_1: 0.8618 - 10s/epoch - 2ms/step\n",
      "Epoch 4/8\n",
      "4500/4500 - 10s - loss: 0.8667 - auc_1: 0.8667 - 10s/epoch - 2ms/step\n",
      "Epoch 5/8\n",
      "4500/4500 - 10s - loss: 0.8593 - auc_1: 0.8690 - 10s/epoch - 2ms/step\n",
      "Epoch 6/8\n",
      "4500/4500 - 10s - loss: 0.8522 - auc_1: 0.8714 - 10s/epoch - 2ms/step\n",
      "Epoch 7/8\n",
      "4500/4500 - 10s - loss: 0.8479 - auc_1: 0.8727 - 10s/epoch - 2ms/step\n",
      "Epoch 8/8\n",
      "4500/4500 - 10s - loss: 0.8438 - auc_1: 0.8740 - 10s/epoch - 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "4500/4500 - 10s - loss: 1.1580 - auc_2: 0.8102 - 10s/epoch - 2ms/step\n",
      "Epoch 2/8\n",
      "4500/4500 - 10s - loss: 0.9329 - auc_2: 0.8446 - 10s/epoch - 2ms/step\n",
      "Epoch 3/8\n",
      "4500/4500 - 10s - loss: 0.9257 - auc_2: 0.8464 - 10s/epoch - 2ms/step\n",
      "Epoch 4/8\n",
      "4500/4500 - 10s - loss: 0.8945 - auc_2: 0.8570 - 10s/epoch - 2ms/step\n",
      "Epoch 5/8\n",
      "4500/4500 - 10s - loss: 0.8818 - auc_2: 0.8615 - 10s/epoch - 2ms/step\n",
      "Epoch 6/8\n",
      "4500/4500 - 10s - loss: 0.8953 - auc_2: 0.8586 - 10s/epoch - 2ms/step\n",
      "Epoch 7/8\n",
      "4500/4500 - 10s - loss: 0.8679 - auc_2: 0.8665 - 10s/epoch - 2ms/step\n",
      "Epoch 8/8\n",
      "4500/4500 - 10s - loss: 0.8654 - auc_2: 0.8674 - 10s/epoch - 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  2.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "4500/4500 - 10s - loss: 1.0515 - auc_3: 0.8039 - 10s/epoch - 2ms/step\n",
      "Epoch 2/8\n",
      "4500/4500 - 10s - loss: 0.9306 - auc_3: 0.8424 - 10s/epoch - 2ms/step\n",
      "Epoch 3/8\n",
      "4500/4500 - 10s - loss: 0.9126 - auc_3: 0.8494 - 10s/epoch - 2ms/step\n",
      "Epoch 4/8\n",
      "4500/4500 - 10s - loss: 0.9058 - auc_3: 0.8513 - 10s/epoch - 2ms/step\n",
      "Epoch 5/8\n",
      "4500/4500 - 10s - loss: 0.8916 - auc_3: 0.8583 - 10s/epoch - 2ms/step\n",
      "Epoch 6/8\n",
      "4500/4500 - 10s - loss: 0.8792 - auc_3: 0.8618 - 10s/epoch - 2ms/step\n",
      "Epoch 7/8\n",
      "4500/4500 - 11s - loss: 0.8696 - auc_3: 0.8649 - 11s/epoch - 2ms/step\n",
      "Epoch 8/8\n",
      "4500/4500 - 10s - loss: 0.8685 - auc_3: 0.8650 - 10s/epoch - 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  4.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "4500/4500 - 11s - loss: 1.0147 - auc_4: 0.8181 - 11s/epoch - 2ms/step\n",
      "Epoch 2/8\n",
      "4500/4500 - 10s - loss: 0.8898 - auc_4: 0.8587 - 10s/epoch - 2ms/step\n",
      "Epoch 3/8\n",
      "4500/4500 - 10s - loss: 0.8695 - auc_4: 0.8656 - 10s/epoch - 2ms/step\n",
      "Epoch 4/8\n",
      "4500/4500 - 10s - loss: 0.8569 - auc_4: 0.8698 - 10s/epoch - 2ms/step\n",
      "Epoch 5/8\n",
      "4500/4500 - 10s - loss: 0.8473 - auc_4: 0.8729 - 10s/epoch - 2ms/step\n",
      "Epoch 6/8\n",
      "4500/4500 - 10s - loss: 0.8415 - auc_4: 0.8747 - 10s/epoch - 2ms/step\n",
      "Epoch 7/8\n",
      "4500/4500 - 10s - loss: 0.8354 - auc_4: 0.8766 - 10s/epoch - 2ms/step\n",
      "Epoch 8/8\n",
      "4500/4500 - 10s - loss: 0.8303 - auc_4: 0.8781 - 10s/epoch - 2ms/step\n",
      "Epoch 1/8\n",
      "4500/4500 - 12s - loss: 1.0188 - auc_5: 0.8153 - 12s/epoch - 3ms/step\n",
      "Epoch 2/8\n",
      "4500/4500 - 11s - loss: 0.8927 - auc_5: 0.8576 - 11s/epoch - 2ms/step\n",
      "Epoch 3/8\n",
      "4500/4500 - 11s - loss: 0.8758 - auc_5: 0.8634 - 11s/epoch - 2ms/step\n",
      "Epoch 4/8\n",
      "4500/4500 - 11s - loss: 0.8623 - auc_5: 0.8680 - 11s/epoch - 2ms/step\n",
      "Epoch 5/8\n",
      "4500/4500 - 10s - loss: 0.8533 - auc_5: 0.8708 - 10s/epoch - 2ms/step\n",
      "Epoch 6/8\n",
      "4500/4500 - 10s - loss: 0.8449 - auc_5: 0.8735 - 10s/epoch - 2ms/step\n",
      "Epoch 7/8\n",
      "4500/4500 - 10s - loss: 0.8393 - auc_5: 0.8752 - 10s/epoch - 2ms/step\n",
      "Epoch 8/8\n",
      "4500/4500 - 10s - loss: 0.8358 - auc_5: 0.8763 - 10s/epoch - 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  7.0min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    6.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    9.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   15.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  3.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  5.4min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  8.9min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   46.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  1.5min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  2.3min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  3.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=143, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('lr',\n",
       "                                Pipeline(steps=[('sc', StandardScaler()),\n",
       "                                                ('lr',\n",
       "                                                 LogisticRegression(C=0.1,\n",
       "                                                                    class_weight='balanced',\n",
       "                                                                    l1_ratio=1,\n",
       "                                                                    penalty='elasticnet',\n",
       "                                                                    solver='saga'))])),\n",
       "                               ('nn',\n",
       "                                Pipeline(steps=[('nn',\n",
       "                                                 <keras.wrappers.scikit_learn.KerasClassifier object at 0x0000021FD1D2C670>)])),\n",
       "                               ('nb', GaussianNB()),\n",
       "                               ('rf',\n",
       "                                RandomForestClassifier(class_weight='...\n",
       "                                DecisionTreeClassifier(class_weight='balanced',\n",
       "                                                       max_depth=5,\n",
       "                                                       max_leaf_nodes=9,\n",
       "                                                       min_samples_leaf=5))],\n",
       "                   final_estimator=LGBMClassifier(boost_from_average=True,\n",
       "                                                  colsample_bytree=0.5178695836798571,\n",
       "                                                  is_unbalance=True,\n",
       "                                                  metric='auc',\n",
       "                                                  min_data_in_leaf=143,\n",
       "                                                  num_leaves=151,\n",
       "                                                  objective='binary',\n",
       "                                                  subsample=1,\n",
       "                                                  subsample_freq=7),\n",
       "                   n_jobs=1, passthrough=True, stack_method='predict_proba',\n",
       "                   verbose=4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack.fit(X = X_train, y = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68714937",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = stack.predict_proba(X = X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db37d9cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9090680840764225"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_pred[:, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
